---
title: Streaming
sidebarTitle: Streaming
layout: ../_core/DocsLayout
category: Learn
sublinks: Introduction, Features, Advanced
permalink: /learn/streaming/
next: /learn/caching/
---

# Streaming

## Introduction
While Batch processing is need for some cases, such as gathering and data enrichment, there are other cases where the data is generated continuously, which typically send in the data records simultaneously. Streaming data includes a wide variety of data such as log files generated by customers using your mobile or web applications, eCommerce purchases, in-game player activity, information from social networks, financial trading floors, or geospatial services telemetry from connected devices or instrumentation in data centers.  
HKube's data streaming is an extension to HKube batch processing pipeline architecture that handles millions of events at scale,
In real-time. As a result, you can collect, analyze, and store large amounts of information.
That capability allows for applications, analytics, and reporting in real-time.

![StreamingDiagram](../../img/streaming/Streaming-diagram-nobackground.png)

### Use Cases - Stream Tweets in real-time
So where are HKube data streams good for? Let's take a look at a stream from Twitter as an example. In this particular case, we want to enrich the data from other resources, such as Facebook, LinkedIn, and other internal databases before saving it.
The process is as follows:

- Stream Tweets in Real-Time: Use the Twitter API and HKube Streaming to get and analyze real-time tweets for your research.
- twitt node: The "twitt" node subscribes to the Twitter API and receives real-time tweets.
- sort node: The "sort" node sorts the tweets based on their language and routes them accordingly.
- Nodes "A" and "B" analyze the tweet messages and save them to the database.

## Features
HKube streaming pipeline supports:

### Unique data transportation
HKube has its own data transportation system, enabling direct data transfer between nodes in a manner that ensures the following

- The data will maintain its order.
- High throughput with low latency.
- High scalability.

***

### Autoscaling
The throughput of streaming can vary over time, allowing us to handle bursts and free up resources for other jobs when they are not needed.
With its own unique heuristic system, HKube is able to recognize changes in throughput and act quickly to support these needs.
To better understand this, let's look at a scenario that demonstrates how HKube handles pressure.

#### Scaling Range
Autoscaling is used by each node by adjusting the number of pods it uses within the specified min-max range.
By using autoscaling, we shut down unnecessary pods to maintain efficiency.
HKube allows to adjust the minimum and maximum number of pods for stateless node:

**Minimum:**

- Defines the minimum number of pods for a stateless node.
- The number of running pods can't be lower than the pre-defined minimum.
- When the application starts, the stateless node will initialize at application up-time, which may be more time-efficient.
- This setting it essential when the resource is needed at up-time.

**Maximum:**

- Defines the maximum number of pods for a stateless node.
- The number of running pods can't be higher than the pre-defined maximum.
- It can be toggled off, in which case the system has no maximum limit.
- This setting is essential when it's necessary to limit the given resources.

***

### Comprehensive Statistics
HKube shows detail statistics between every node, which can be used to analyze the relationship between them.
By using the statistics, you can achieve data about the requests and responses, as follows:

- **currentSize:** How many pods there are, which are running the algorithm.
- **reqRate:** The rate of incoming request messages, calculated as (Δ message count) / (Δ time in seconds).
- **queueSize:** Total number of requests in the queue, waiting to be handled.
- **avgQueueSize:** Average number of requests in the queue.
- **processingTimeMs:** Average processing time in ms for all the requests.
- **roundTripTimeMs:** Average trip time in ms for all the requests (trip is the total time from when a request was created to when it was successfully handled).
- **queueTimeMs:** The average of how long requests are in queue.
- **durationRate:** The average of all the positive durations, which duration is the amount of time it took to handle a request.
- **grossDurationRate:** 
- **throughput:** 
- **totalRequests:** The total amount of requests sent.
- **totalResponses:** The total amount of responses sent (handled requests).
- **totalDropped:** The total amount of requests which didn't response back (?).

The followings are additional statistics that are specially between stateful to stateless algotihems:
- **required:** How many pods are requried, according to load.
- **desired:** How many pods are desired.
- **status:** Status of the node.

***

### Conditional Data Flows:
In streaming data, most of the time, we expect the data to follow a specific flow. However, there are scenarios where we need to dynamically change this flow. To illustrate, let's consider the Twitter use case: typically, we aim to enrich the data with additional information from other resources. However, there may be instances where we are unable to identify the author of a post. In such cases, we need to establish additional prerequisites before proceeding with the enrichment. HKube assists in handling such situations with conditional data flow. We will explain how to create and work with this feature later.

***

### How to Work with Streaming Pipelines
Streaming pipelines are built from Stateful and Stateless algorithms.

#### Stateful Algorithm:
- A stateful algorithm is tailored for a specific execution.
- The stateful algorithm must use HKube's SDK to decide on which flow the data should continue: the default one or one of the conditionals.
- Only one stateful algorithm can be executed for each algorithm kind in a specific execution.
- There can be multiple stateful algorithms with different node names.
- The stateful algorithm will be closed if one of the following occurs:
	- The execution is terminated by the client using HKube's API.
	- The main function of the algorithm returns.

#### Stateless Algorithm:
- A stateless algorithm can serve multiple executions throughout its life.
- The stateless algorithm can dynamically scale (up/down) according to the job’s needs.
- Upon failure, HKube will skip the current execution for performance reasons.
- The stateless algorithm doesn't need to use HKube's API to continue the flow; this happens after the return command.
- Scaling up stateless algorithm depends on:
	- The sending node's queue size.
	- The rate of increase/decrease in queue size.
	- The processing time of the receiving node.

#### Streaming Flow:
- The flow represents the movement of data through the pipeline nodes (The flow must start with a Stateful Node/Algorithm).
- You can have more than 1 flow in every pipeline, each flow has it's unique name.
- Streaming flows are defined in a simple syntax, >> used for defining a streaming node flow, & for and, | for different streaming flow. Examples:
    - Flow named flow1, is from node A streams to nodes B and C, node B stream to node D. Syntax would be: A >> B&C | B >> D.

    ```json
{
    "streaming": {
        "flows": {
            "flow1": "A >> B&C | B >> D",
        },
        "defaultFlow": "master"
    }
}
```
![StreamFlowExample1](../../img/streaming/StreamingFlowExample1.png)

    - Flow named analyze, is from node sort which streams to node A. Syntax would be sort >> A
    Also, flow named master, is from node twitt which streams to node sort that streams to node B. Syntax would be twitt >> sort >> B.
```json
{
    "streaming": {
        "flows": {
            "analyze": "sort>>A",
            "master": "twitt >>sort>>B"
        },
        "defaultFlow": "master"
    }
}
```
![StreamFlowExample2](../../img/streaming/StreamingFlowExample2.png)

### Advanced

#### HKUBE API STREAMING METHODS for Stateful Algorithm

- **sendMessage(msg, flowName)**
    - This method passes on a message to the next node in the pipeline flow.
    - Parameters:
        - msg: A created message as desired to be obtained by the next node.
        - flowName: The name of the flow of nodes defined in the pipeline definition. This parameter should be given only if a new flow is initiated (not if the processing is already in the middle of a flow). If no flow name is given and the node is not in the middle of a flow initiated earlier, the default flow defined in the pipeline definition will be used as a flow name.
- **registerInputListener(onMessage=handleMessage)**
    - This method is used only within a stateful algorithm. It allows registering a method written by the algorithm implementor, which will be invoked upon each message that arrives.
    - The onMessage signature is onMessage(msg, origin), where the origin is the name of the previous node.

- **startMessageListening()**
    - This method is used only within a stateful algorithm. Once all message handlers have been registered using registerInputListener, startMessageListening needs to be invoked to start receiving messages upon arrival.